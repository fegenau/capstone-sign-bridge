# ğŸ”„ GuÃ­a de MigraciÃ³n - MonolÃ­tica â†’ ProducciÃ³n

**Objetivo:** Convertir MonolithicDetectionScreen.js en componentes modulares y reutilizables
**DuraciÃ³n estimada:** 2-3 horas
**Complejidad:** Media

---

## ğŸ“‹ Resumen de Cambios

```
MonolithicDetectionScreen.js (1 archivo, 600+ lÃ­neas)
              â†“ REFACTORIZACIÃ“N
Fase 1: Extraer Hooks
  â”œâ”€ hooks/useMonolithicModel.js
  â”œâ”€ hooks/useMonolithicMediaPipe.js
  â””â”€ hooks/useMonolithicDetection.js

Fase 2: Crear Servicios
  â”œâ”€ utils/services/monolithicModelService.js
  â”œâ”€ utils/services/monolithicMediaPipeService.js
  â””â”€ utils/services/monolithicDetectionService.js

Fase 3: Simplificar Componente
  â””â”€ screens/MonolithicDetectionScreen.js (refactorizado)

Fase 4: Crear Variantes
  â”œâ”€ screens/WordDetectionScreen.mediapipe.js (actualizado)
  â”œâ”€ screens/AlphabetDetectionScreen.js (actualizado)
  â””â”€ screens/NumberDetectionScreen.js (actualizado)

Resultado: Componentes modulares + reutilizaciÃ³n
```

---

## ğŸ¯ Fase 1: Extraer Hooks

### 1.1 Crear `hooks/useMonolithicModel.js`

```javascript
/**
 * Hook para cargar y gestionar el modelo TensorFlow.js
 */
import { useState, useCallback } from 'react';
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
import { Asset } from 'expo-asset';

export const useMonolithicModel = () => {
  const [model, setModel] = useState(null);
  const [labels, setLabels] = useState([]);
  const [isReady, setIsReady] = useState(false);
  const [error, setError] = useState(null);

  const loadLabels = useCallback(async () => {
    try {
      const labelsAsset = Asset.fromModule(
        require('../assets/model/labels.json')
      );
      await labelsAsset.downloadAsync();

      const response = await fetch(labelsAsset.uri);
      const data = await response.json();
      const loadedLabels = data.classes || data;

      setLabels(loadedLabels);
      return loadedLabels;
    } catch (err) {
      setError(err.message);
      throw err;
    }
  }, []);

  const loadModel = useCallback(async () => {
    try {
      await tf.ready();

      const loadedLabels = await loadLabels();

      const modelAsset = Asset.fromModule(
        require('../assets/model/tfjs_model/model.json')
      );
      await modelAsset.downloadAsync();

      const loadedModel = await tf.loadLayersModel(modelAsset.uri);

      // Warmup
      const dummyInput = tf.randomNormal([1, 24, 126]);
      const warmupPred = loadedModel.predict(dummyInput);
      dummyInput.dispose();
      warmupPred.dispose();

      setModel(loadedModel);
      setIsReady(true);

      return { model: loadedModel, labels: loadedLabels };
    } catch (err) {
      setError(err.message);
      throw err;
    }
  }, [loadLabels]);

  const predict = useCallback(
    async (frameBuffer) => {
      if (!model || frameBuffer.length < 24) {
        return null;
      }

      try {
        const inputTensor = tf.tensor3d([frameBuffer], [1, 24, 126]);
        const outputTensor = model.predict(inputTensor);
        const predictions = await outputTensor.data();
        const predictionsArray = Array.from(predictions);

        const maxIdx = predictionsArray.indexOf(Math.max(...predictionsArray));
        const maxConfidence = predictionsArray[maxIdx];

        inputTensor.dispose();
        outputTensor.dispose();

        return {
          word: labels[maxIdx],
          confidence: maxConfidence,
          index: maxIdx,
          allPredictions: predictionsArray,
        };
      } catch (err) {
        setError(err.message);
        return null;
      }
    },
    [model, labels]
  );

  return {
    model,
    labels,
    isReady,
    error,
    loadModel,
    predict,
  };
};
```

### 1.2 Crear `hooks/useMonolithicMediaPipe.js`

```javascript
/**
 * Hook para MediaPipe Hand Detection
 */
import { useState, useCallback, useRef } from 'react';

export const useMonolithicMediaPipe = () => {
  const [handDetector, setHandDetector] = useState(null);
  const [isReady, setIsReady] = useState(false);
  const [error, setError] = useState(null);

  const lastFrameTime = useRef(0);

  const initialize = useCallback(async () => {
    try {
      const vision = await import('@mediapipe/tasks-vision');

      if (!vision || !vision.HandLandmarker) {
        throw new Error('MediaPipe Vision no disponible');
      }

      const detector = await vision.HandLandmarker.createFromOptions(
        window,
        {
          baseOptions: {
            modelAssetPath:
              'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm',
          },
          runningMode: 'VIDEO',
          numHands: 2,
          minHandDetectionConfidence: 0.5,
        }
      );

      setHandDetector(detector);
      setIsReady(true);

      return detector;
    } catch (err) {
      setError(err.message);
      throw err;
    }
  }, []);

  const detectHands = useCallback(
    async (video) => {
      if (!handDetector || !video) return null;

      try {
        const now = Date.now();

        // Control FPS
        if (now - lastFrameTime.current < 33) {
          return null;
        }
        lastFrameTime.current = now;

        const detectionResult = await handDetector.detectForVideo(video, now);

        if (!detectionResult || !detectionResult.landmarks) {
          return null;
        }

        let leftHand = null;
        let rightHand = null;

        detectionResult.handedness?.forEach((handedness, idx) => {
          if (handedness[0].categoryName === 'Left') {
            leftHand = { landmarks: detectionResult.landmarks[idx] };
          } else {
            rightHand = { landmarks: detectionResult.landmarks[idx] };
          }
        });

        return { leftHand, rightHand };
      } catch (err) {
        setError(err.message);
        return null;
      }
    },
    [handDetector]
  );

  return {
    handDetector,
    isReady,
    error,
    initialize,
    detectHands,
  };
};
```

### 1.3 Crear `hooks/useMonolithicDetection.js`

```javascript
/**
 * Hook que orquesta todo: Model + MediaPipe + Buffer
 */
import { useState, useCallback, useRef, useEffect } from 'react';
import { useMonolithicModel } from './useMonolithicModel';
import { useMonolithicMediaPipe } from './useMonolithicMediaPipe';

export const useMonolithicDetection = ({ videoRef, onDetection }) => {
  const [frameBuffer, setFrameBuffer] = useState([]);
  const [isDetecting, setIsDetecting] = useState(false);

  const modelHook = useMonolithicModel();
  const mediaPipeHook = useMonolithicMediaPipe();

  const animationFrameId = useRef(null);

  // Normalizar keypoints
  const normalizeKeypoints = useCallback((keypoints) => {
    if (!keypoints) return null;
    return keypoints.map((val) => Math.max(0, Math.min(1, val)));
  }, []);

  // Combinar manos
  const combineHandKeypoints = useCallback(
    (leftHand, rightHand) => {
      const combined = new Array(126).fill(0);

      if (leftHand && leftHand.landmarks) {
        let idx = 0;
        leftHand.landmarks.forEach((landmark) => {
          combined[idx++] = landmark.x || 0;
          combined[idx++] = landmark.y || 0;
          combined[idx++] = landmark.z || 0;
        });
      }

      if (rightHand && rightHand.landmarks) {
        let idx = 63;
        rightHand.landmarks.forEach((landmark) => {
          combined[idx++] = landmark.x || 0;
          combined[idx++] = landmark.y || 0;
          combined[idx++] = landmark.z || 0;
        });
      }

      return normalizeKeypoints(combined);
    },
    [normalizeKeypoints]
  );

  // Loop de detecciÃ³n
  const detectionLoop = useCallback(async () => {
    if (!isDetecting || !videoRef?.current) return;

    try {
      const hands = await mediaPipeHook.detectHands(videoRef.current);

      if (hands) {
        const keypoints = combineHandKeypoints(
          hands.leftHand,
          hands.rightHand
        );

        if (keypoints) {
          setFrameBuffer((prev) => {
            const newBuffer = [...prev];
            if (newBuffer.length >= 24) newBuffer.shift();
            newBuffer.push(keypoints);

            // Si tenemos 24 frames, hacer predicciÃ³n
            if (newBuffer.length === 24) {
              (async () => {
                const prediction = await modelHook.predict(newBuffer);
                if (prediction && onDetection) {
                  onDetection(prediction);
                }
              })();
            }

            return newBuffer;
          });
        }
      }
    } catch (error) {
      console.error('Detection error:', error);
    }

    animationFrameId.current = requestAnimationFrame(detectionLoop);
  }, [isDetecting, videoRef, mediaPipeHook, combineHandKeypoints, modelHook, onDetection]);

  // Inicializar modelo y MediaPipe
  useEffect(() => {
    const init = async () => {
      await modelHook.loadModel();
      await mediaPipeHook.initialize();
    };
    init();
  }, [modelHook, mediaPipeHook]);

  // Iniciar/parar detection loop
  useEffect(() => {
    if (isDetecting && mediaPipeHook.isReady) {
      animationFrameId.current = requestAnimationFrame(detectionLoop);
    }
    return () => {
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
      }
    };
  }, [isDetecting, mediaPipeHook.isReady, detectionLoop]);

  const startDetection = useCallback(() => {
    setFrameBuffer([]);
    setIsDetecting(true);
  }, []);

  const stopDetection = useCallback(() => {
    setIsDetecting(false);
  }, []);

  return {
    startDetection,
    stopDetection,
    isDetecting,
    frameBuffer,
    modelReady: modelHook.isReady,
    mediaPipeReady: mediaPipeHook.isReady,
    error: modelHook.error || mediaPipeHook.error,
  };
};
```

---

## ğŸ¯ Fase 2: Crear Servicios

### 2.1 Consolidar en un Servicio

```javascript
// utils/services/monolithicDetectionService.js

import * as tf from '@tensorflow/tfjs';
import { Asset } from 'expo-asset';

export class MonolithicDetectionService {
  constructor() {
    this.model = null;
    this.labels = [];
    this.handDetector = null;
    this.callbacks = [];
  }

  async loadModel() {
    // Implementar lÃ³gica de loadTensorFlowModel()
  }

  async initMediaPipe() {
    // Implementar lÃ³gica de initializeMediaPipe()
  }

  async detectHands(video) {
    // Implementar lÃ³gica de detectHandsInFrame()
  }

  async predict(frameBuffer) {
    // Implementar lÃ³gica de predictWithModel()
  }

  onDetection(callback) {
    this.callbacks.push(callback);
  }

  notifyCallbacks(data) {
    this.callbacks.forEach((cb) => cb(data));
  }
}

export const monolithicDetectionService = new MonolithicDetectionService();
```

---

## ğŸ¯ Fase 3: Simplificar Componente

Refactorizar `MonolithicDetectionScreen.js` para usar hooks:

```javascript
import { useMonolithicDetection } from '../hooks/useMonolithicDetection';

const MonolithicDetectionScreen = ({ navigation }) => {
  const videoRef = useRef(null);
  const [detectedWord, setDetectedWord] = useState(null);
  const [confidence, setConfidence] = useState(0);

  const { startDetection, stopDetection, frameBuffer } =
    useMonolithicDetection({
      videoRef,
      onDetection: ({ word, confidence }) => {
        setDetectedWord(word);
        setConfidence(confidence);
      },
    });

  // Render simplificado...
};
```

---

## ğŸ¯ Fase 4: Tests

```javascript
// __tests__/monolithicDetection.test.js

describe('MonolithicDetection', () => {
  test('loadModel carga correctamente', async () => {
    const service = new MonolithicDetectionService();
    await service.loadModel();

    expect(service.model).toBeDefined();
    expect(service.labels.length).toBeGreaterThan(0);
  });

  test('detectHands retorna landmarks vÃ¡lidos', async () => {
    // Mock video
    const mockVideo = {
      videoWidth: 640,
      videoHeight: 480,
    };

    const hands = await service.detectHands(mockVideo);
    expect(hands).toHaveProperty('leftHand', 'rightHand');
  });

  test('predict retorna predicciÃ³n vÃ¡lida', async () => {
    const mockBuffer = Array(24).fill(Array(126).fill(0.5));
    const prediction = await service.predict(mockBuffer);

    expect(prediction).toHaveProperty('word', 'confidence', 'index');
  });
});
```

---

## âœ… Checklist de MigraciÃ³n

- [ ] Crear `hooks/useMonolithicModel.js`
- [ ] Crear `hooks/useMonolithicMediaPipe.js`
- [ ] Crear `hooks/useMonolithicDetection.js`
- [ ] Crear `utils/services/monolithicDetectionService.js`
- [ ] Refactorizar `MonolithicDetectionScreen.js`
- [ ] Actualizar `WordDetectionScreen.mediapipe.js` para usar hooks
- [ ] Actualizar `AlphabetDetectionScreen.js`
- [ ] Actualizar `NumberDetectionScreen.js`
- [ ] Escribir tests
- [ ] Validar performance
- [ ] Documentar cambios

---

## ğŸ“Š ComparaciÃ³n: Antes vs DespuÃ©s

### ANTES (MonolÃ­tica)

```
MonolithicDetectionScreen.js
â”œâ”€ State: modelo, mediaipe, buffer, UI
â”œâ”€ LÃ³gica: loadModel, initMediaPipe, detect
â”œâ”€ UI: render
â””â”€ PROBLEMAS:
    âŒ DifÃ­cil de mantener
    âŒ No reutilizable
    âŒ Acoplada
    âŒ DifÃ­cil de testear
```

### DESPUÃ‰S (Modular)

```
Hooks (reutilizables)
â”œâ”€ useMonolithicModel
â”œâ”€ useMonolithicMediaPipe
â””â”€ useMonolithicDetection

Services (lÃ³gica centralizada)
â””â”€ MonolithicDetectionService

Components (UI limpia)
â”œâ”€ MonolithicDetectionScreen (refactorizado)
â”œâ”€ WordDetectionScreen (usa hooks)
â”œâ”€ AlphabetDetectionScreen (usa hooks)
â””â”€ NumberDetectionScreen (usa hooks)

Tests
â””â”€ monolithicDetection.test.js

BENEFICIOS:
âœ… FÃ¡cil de mantener
âœ… Reutilizable
âœ… Desacoplado
âœ… FÃ¡cil de testear
âœ… Performance mejorado
```

---

## ğŸš€ Detalles de EjecuciÃ³n

### Paso 1: Crear Hooks

**Tiempo:** 45 minutos

1. Copiar cÃ³digo de `MonolithicDetectionScreen`
2. Dividir por concerns (modelo, mediaipe, detecciÃ³n)
3. Usar `useCallback` y `useRef` apropiadamente
4. Testear cada hook aisladamente

### Paso 2: Crear Servicios

**Tiempo:** 30 minutos

1. Consolidar lÃ³gica comÃºn
2. Usar patrÃ³n Singleton
3. Implementar Observer pattern para callbacks

### Paso 3: Refactorizar Componente

**Tiempo:** 30 minutos

1. Reemplazar setState con hooks
2. Simplificar JSX
3. Mantener debugging (logs)

### Paso 4: Integrar en Otros Componentes

**Tiempo:** 45 minutos

1. WordDetectionScreen.mediapipe
2. AlphabetDetectionScreen
3. NumberDetectionScreen

### Paso 5: Tests

**Tiempo:** 30 minutos

1. Unit tests para hooks
2. Integration tests para servicios
3. E2E tests para componentes

---

## ğŸ“ Lecciones Aprendidas

1. **Empezar monolÃ­tico para entender el flujo**
2. **Luego extraer hooks para reutilizaciÃ³n**
3. **Crear servicios para lÃ³gica centralizada**
4. **Separar UI de lÃ³gica**
5. **Testear cada parte aisladamente**

---

## ğŸ“š Recursos

- [Hooks API Reference](https://react.dev/reference/react/hooks)
- [Custom Hooks](https://react.dev/learn/reusing-logic-with-custom-hooks)
- [Testing Library](https://testing-library.com/)

---

**Status:** GuÃ­a completa âœ…
**Ãšltima actualizaciÃ³n:** 2025-11-13
