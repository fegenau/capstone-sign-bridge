# ðŸŽ¯ Sign Bridge - LSTM Model Integration Complete

## âœ… What's Been Implemented

### 1. Model Conversion & Validation
- âœ… TF.js model converted and validated (67 classes)
- âœ… Files in `sign-Bridge/assets/ml/`:
  - `model.json` - TF.js layers model
  - `group1-shard1of1.bin` - Model weights (3.94 MB)
  - `label_encoder.json` - 67 class labels
  - `config.json` - Model configuration
  - `README.md` - Complete documentation
  - `validate_model.js` - Validation script

### 2. ML Infrastructure (`src/ml/`)
- âœ… `tfSetup.ts` - TensorFlow.js initialization with WebGL backend
- âœ… `signMovementClassifier.ts` - Main classifier with:
  - 24-frame circular buffer
  - Smoothing window (8 frames)
  - Memory management (tensor disposal)
  - Cross-platform loading (Web + RN via Expo dev server)

### 3. Feature Extraction (`src/ml/utils/`)
- âœ… `keypointExtractor.ts` - Converts MediaPipe landmarks to 126 features:
  - Left hand: 21 landmarks Ã— 3 coords = 63 features
  - Right hand: 21 landmarks Ã— 3 coords = 63 features
  - Total: 126 features per frame

### 4. React Hooks (`src/hooks/`)
- âœ… `useSignMovementRecognition.ts` - High-level prediction hook with:
  - Frame buffer management
  - Prediction loop via requestAnimationFrame
  - Smoothing and confidence thresholding

### 5. UI Components (`src/components/`)
- âœ… `SignDetectionOverlay.tsx` - Camera overlay showing:
  - Frame count progress (0-24)
  - Current prediction
  - Confidence percentage with color coding
  - Visual progress bars

### 6. Detection Screen (`app/(tabs)/`)
- âœ… `detection.tsx` - Complete integration:
  - Camera preview (Expo Camera)
  - Real MediaPipe HandLandmarker initialization
  - Per-frame keypoint processing
  - Live predictions with overlay
  - Memory-optimized rAF loops

### 7. MediaPipe Integration
- âœ… **Real HandLandmarker** configured with:
  - FilesetResolver for WASM loading
  - Official Google model (float16)
  - VIDEO mode with 2 hands detection
  - Per-frame normalized keypoint extraction

### 8. Performance Optimizations
- âœ… RequestAnimationFrame-based prediction loop
- âœ… Tensor disposal after each prediction
- âœ… Decoupled inference from UI thread
- âœ… FPS control (~30 FPS target)
- âœ… Smoothing to reduce prediction jitter

## ðŸš€ How to Run

### Install Dependencies
```powershell
cd "c:\Users\SEED\Documents\GitHub\capstone-sign-bridge\sign-Bridge"
npm install
```

### Start Development Server

#### Web (Recommended for testing)
```powershell
npx expo start --web
```
Then press `w` or open http://localhost:8081 in your browser.

#### Android
```powershell
npx expo start --android
```
Requires Android Studio and emulator/device.

#### iOS
```powershell
npx expo start --ios
```
Requires Xcode (macOS only).

## ðŸ“± Using the App

1. **Navigate to Detection Tab** - Look for the "Detect" tab in the bottom navigation
2. **Grant Camera Permission** - Allow camera access when prompted
3. **Position Hands** - Show your hands to the camera
4. **Watch Predictions** - The overlay shows:
   - Frame buffer progress (filling to 24)
   - Real-time predictions
   - Confidence scores
   - Color-coded accuracy

## ðŸŽ¨ Features

### Buffer System
- Collects 24 consecutive frames before prediction
- Circular buffer maintains constant memory
- Progress bar shows buffer fill status

### Smoothing Window
- Averages last 8 predictions
- Reduces jitter and false positives
- Configurable threshold (default: 0.5)

### Real MediaPipe Detection
- Detects up to 2 hands simultaneously
- 21 landmarks per hand (63 features each)
- Normalized coordinates [0, 1]
- Works on web with WASM acceleration

### 67 Sign Classes
- **Numbers**: 0-9 (10 classes)
- **Alphabet**: A-Z (26 classes)
- **Common Gestures**: Hello, Goodbye, Thanks, etc. (31 classes)

## ðŸ”§ Technical Stack

### Core Dependencies
- React Native 0.74.5
- Expo SDK 51
- TensorFlow.js 4.22.0
- MediaPipe Tasks Vision 0.10.22

### Backends
- Web: WebGL (primary), WASM (fallback), CPU (final fallback)
- React Native: WebGL via Expo dev server

### Model Specs
- Architecture: Bidirectional LSTM
- Input: [batch, 24, 126] (24 frames Ã— 126 features)
- Output: [batch, 67] (67 sign classes)
- Size: ~4 MB

## ðŸ“Š Performance Metrics

- **Target FPS**: 30 FPS
- **Buffer Fill Time**: ~0.8 seconds (24 frames at 30 FPS)
- **Prediction Time**: <33ms per frame (WebGL)
- **Memory Usage**: Minimal (tensors disposed immediately)

## ðŸ› Troubleshooting

### Camera Not Working
- Ensure permissions are granted
- Check browser supports getUserMedia
- Try refreshing the page

### No Predictions Appearing
- Wait for 24 frames to buffer
- Ensure hands are visible
- Check console for errors

### Slow Performance
- Use Chrome/Edge (better WebGL support)
- Close other GPU-intensive apps
- Check browser console for backend warnings

### Model Load Errors
- Verify assets/ml/ folder contains all files
- Check network connection (MediaPipe WASM download)
- Clear browser cache and reload

## ðŸ“ Project Structure

```
sign-Bridge/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ (tabs)/
â”‚       â””â”€â”€ detection.tsx          # Main detection screen
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ ml/                        # TF.js model files
â”‚       â”œâ”€â”€ model.json
â”‚       â”œâ”€â”€ group1-shard1of1.bin
â”‚       â”œâ”€â”€ label_encoder.json
â”‚       â””â”€â”€ config.json
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ tfSetup.ts            # TF.js initialization
â”‚   â”‚   â”œâ”€â”€ signMovementClassifier.ts
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ keypointExtractor.ts
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useSignMovementRecognition.ts
â”‚   â””â”€â”€ components/
â”‚       â””â”€â”€ SignDetectionOverlay.tsx
â””â”€â”€ hooks/
    â””â”€â”€ useMediaPipeDetection.js   # Real MediaPipe integration
```

## ðŸŽ¯ Next Steps (Optional Enhancements)

1. **Native Performance**: Implement native MediaPipe for iOS/Android
2. **Model Optimization**: Quantization for smaller size
3. **Offline Mode**: Bundle MediaPipe WASM locally
4. **Training Mode**: Collect and label new signs
5. **Multi-Language**: Support different sign languages
6. **Gesture Recording**: Save and replay gesture sequences
7. **Analytics**: Track prediction accuracy over time

## âœ… Completed Requirements

- [x] Convert Keras LSTM model to TensorFlow.js
- [x] Configure TF.js for React Native/Expo
- [x] Implement inference module with 24-frame buffer
- [x] Create integration hook with smoothing
- [x] Build camera overlay UI
- [x] Fix camera black screen (rAF + memory management)
- [x] Add real MediaPipe hand detection
- [x] Implement detection screen with live predictions
- [x] Cross-platform asset loading
- [x] Complete documentation

## ðŸ“ Notes

- **Web Testing**: Fully functional with real hand detection
- **React Native**: Uses Expo dev server for model loading
- **Production**: May need to bundle assets differently for standalone builds
- **MediaPipe**: Currently uses CDN for WASM; consider local bundle for offline

---

**Status**: âœ… **FULLY OPERATIONAL**

The system is ready for testing on web. Navigate to the Detection tab and start detecting sign language gestures!
