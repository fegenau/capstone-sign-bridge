# ğŸš€ GuÃ­a para Integrar el Modelo TensorFlow Lite Real

## ğŸ“‹ Estado Actual

**âš ï¸ IMPORTANTE**: Actualmente la aplicaciÃ³n estÃ¡ en **MODO SIMULACIÃ“N**. Las detecciones que ves son generadas algorÃ­tmicamente para demostrar la interfaz de usuario, **NO estÃ¡n procesando tu modelo `model_fp16.tflite`**.

## ğŸ”§ Pasos para Integrar tu Modelo Real

### 1. ğŸ“¦ Instalar Dependencias de TensorFlow Lite

Necesitas una librerÃ­a que pueda ejecutar modelos TensorFlow Lite en React Native/Expo:

```bash
# OpciÃ³n 1: TensorFlow Lite para React Native (recomendado)
npm install react-native-tflite

# OpciÃ³n 2: TensorFlow.js (alternativo)
npm install @tensorflow/tfjs @tensorflow/tfjs-react-native @tensorflow/tfjs-platform-react-native
```

### 2. ğŸ”„ Configurar el Modelo en el Hook

Edita el archivo `hooks/useSignLanguageModel.ts`:

```typescript
// En la funciÃ³n loadTensorFlowModel(), reemplaza el contenido con:

import { TensorflowLitePlugin } from 'react-native-tflite';

const loadTensorFlowModel = async () => {
  try {
    // 1. Cargar el modelo
    const modelPath = 'assets/Modelo/v1.0/model_fp16.tflite';
    await TensorflowLitePlugin.loadModel({
      model: modelPath,
      numThreads: 2, // Ajustar segÃºn dispositivo
    });

    // 2. Cargar las etiquetas
    const labelsPath = 'assets/Modelo/v1.0/labels.txt';
    const labelsContent = await loadLabelsFromAssets(labelsPath);
    setLabels(labelsContent);

    // 3. Activar modo real
    setUseRealModel(true);
    console.log('âœ… Modelo TensorFlow Lite cargado exitosamente');
    
  } catch (error) {
    console.error('âŒ Error cargando modelo TensorFlow Lite:', error);
    setUseRealModel(false);
  }
};
```

### 3. ğŸ–¼ï¸ Implementar Procesamiento de ImÃ¡genes

En la funciÃ³n `processImageWithModel()`:

```typescript
const processImageWithModel = async (imageUri: string): Promise<SignDetectionResult> => {
  try {
    // 1. Preprocesar la imagen
    const processedImage = await preprocessImage(imageUri);
    
    // 2. Ejecutar inferencia
    const results = await TensorflowLitePlugin.runInference({
      input: processedImage
    });
    
    // 3. Procesar resultados
    const predictions = results.output;
    const maxIndex = predictions.indexOf(Math.max(...predictions));
    const prediction = labels[maxIndex];
    const confidence = predictions[maxIndex];
    
    return { prediction, confidence };
    
  } catch (error) {
    console.error('âŒ Error en inferencia:', error);
    throw error;
  }
};

const preprocessImage = async (imageUri: string) => {
  // Redimensionar imagen segÃºn las especificaciones de tu modelo
  // Normalizar valores de pÃ­xeles (0-255 â†’ 0-1 o -1-1)
  // Convertir a tensor del formato correcto
  
  // Ejemplo con expo-image-manipulator:
  const manipulatedImage = await ImageManipulator.manipulateAsync(
    imageUri,
    [{ resize: { width: 224, height: 224 } }], // Ajustar al tamaÃ±o de tu modelo
    { compress: 1, format: ImageManipulator.SaveFormat.JPEG }
  );
  
  // Convertir a tensor segÃºn formato esperado por tu modelo
  return processedTensor;
};
```

### 4. ğŸ“± Capturar Frames de la CÃ¡mara

Para detecciÃ³n en tiempo real, necesitas capturar frames de la cÃ¡mara:

```typescript
// En SignDetectionCamera.tsx, usar onCameraReady o similar
const captureCurrentFrame = async () => {
  if (cameraRef.current) {
    const photo = await cameraRef.current.takePictureAsync({
      quality: 0.8,
      skipProcessing: true, // Para mayor velocidad
    });
    return photo.uri;
  }
  throw new Error('CÃ¡mara no disponible');
};
```

### 5. âš™ï¸ Especificaciones de tu Modelo

BasÃ¡ndote en tu modelo `model_fp16.tflite`, necesitas configurar:

```typescript
// Configuraciones especÃ­ficas para tu modelo
const MODEL_CONFIG = {
  inputShape: [1, 224, 224, 3], // Ajustar segÃºn tu modelo
  outputShape: [1, 3], // 3 clases: A, B, C
  inputType: 'float32', // o 'uint8' segÃºn tu modelo
  normalizeInput: true, // Si requiere normalizaciÃ³n 0-1
  labels: ['A', 'B', 'C']
};
```

## ğŸ” Identificar Especificaciones del Modelo

Para conocer las especificaciones exactas de tu modelo:

### OpciÃ³n 1: Usar Netron (Recomendado)
1. Instala Netron: https://netron.app/
2. Abre tu archivo `model_fp16.tflite`
3. Observa:
   - **Input tensor**: tamaÃ±o, formato, tipo de datos
   - **Output tensor**: clases, formato de salida
   - **Arquitectura**: tipo de red neuronal

### OpciÃ³n 2: TensorFlow Lite Tools
```bash
# Instalar herramientas TF Lite
pip install tensorflow

# Analizar modelo
python -c "
import tensorflow as tf
interpreter = tf.lite.Interpreter(model_path='assets/Modelo/v1.0/model_fp16.tflite')
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print('Input shape:', input_details[0]['shape'])
print('Input type:', input_details[0]['dtype'])
print('Output shape:', output_details[0]['shape'])
print('Output type:', output_details[0]['dtype'])
"
```

## ğŸ¯ Checklist de IntegraciÃ³n

- [ ] âœ… Instalar librerÃ­a TensorFlow Lite
- [ ] ğŸ”§ Configurar carga del modelo en `loadTensorFlowModel()`
- [ ] ğŸ–¼ï¸ Implementar `processImageWithModel()` 
- [ ] ğŸ“ Configurar preprocesamiento segÃºn especificaciones del modelo
- [ ] ğŸ¥ Implementar captura de frames en tiempo real
- [ ] ğŸ§ª Probar con imÃ¡genes estÃ¡ticas primero
- [ ] âš¡ Optimizar rendimiento (threads, frecuencia)
- [ ] ğŸ› Manejar errores y fallbacks
- [ ] ğŸ“Š Ajustar umbrales de confianza

## ğŸš§ Problemas Comunes

### Error: "Model format not supported"
- Verificar que el archivo `.tflite` no estÃ© corrupto
- Asegurar compatibilidad de la versiÃ³n de TensorFlow Lite

### Predicciones incorrectas
- Verificar preprocesamiento de imagen (normalizaciÃ³n, redimensionamiento)
- Comprobar que las etiquetas estÃ©n en el orden correcto
- Ajustar iluminaciÃ³n y contraste de la cÃ¡mara

### Rendimiento lento
- Reducir resoluciÃ³n de entrada
- Usar menos threads o ajustar configuraciÃ³n
- Implementar cache de modelos

## ğŸ“ Soporte

Si necesitas ayuda con la integraciÃ³n:

1. **Verifica los logs**: La consola muestra el estado actual (simulaciÃ³n vs real)
2. **Prueba paso a paso**: Comienza con imÃ¡genes estÃ¡ticas antes de tiempo real
3. **Documenta errores**: Guarda logs de errores para debugging

## ğŸ‰ Â¿Todo Listo?

Una vez integrado correctamente, deberÃ­as ver:
- ğŸ¤– **"Modelo IA Real"** en lugar de "Modo SimulaciÃ³n"
- âš¡ Detecciones basadas en las imÃ¡genes reales de la cÃ¡mara
- ğŸ¯ Mayor precisiÃ³n en las predicciones

Â¡Tu aplicaciÃ³n estarÃ¡ lista para detectar seÃ±as reales! ğŸš€